{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusing convolutional and batchnorm layers in TensorFlow\n",
    "\n",
    "- Batchnorm layers can be fused with preceding 2D convolutional layers, into a single convolutional layer.\n",
    "- Batchnorm layers *cannot* be fused with subseqeunt 2D convolutional layers, into a single convolutional layer, *if* that convolutional layer adds padding to its input.\n",
    "- This script demos both types of fusion, and highlights how the fusion can fail in the latter case when padding is used.\n",
    "- Thus, in some models implemented on specialized hardware (e.g., Edge TPU), it is desirable (necessary!) to have an API that implements a batchnorm layer, or at least the broadcasted scaling and shifting that can mimic a static batchnorm layer after training. Moreover, in the case of a sequence of (Conv2D->RELU->BN) layers, the batchnorm layer clearly cannot be fused with the convolutional layer.\n",
    "\n",
    "Batchnorm layers scale and shift the input data, providing normalized data to the subsequent layer. In the original batchnorm [publication](https://arxiv.org/abs/1502.03167), bathnorm layers follow convolutional layers, and precede RELU layers (Conv2D->BN->RELU). Since that publication, many researchers have used batchnorm layers that follow the RELU layer (Conv2D->RELU->BN), claiming superior results.\n",
    "\n",
    "After training, if the moving mean and moving standard deviation of the batchnorm layer are kept fix, then the scaling and shifting parameters *might* be \"fused\" with a preceding or subsequent convolutional layer (by scaling and shifting the parameters of the convolutional layer), thereby allowing the explicit batchnorm layer to be removed (as it will be implicitly implemented by the convolutional layer).\n",
    "\n",
    "For a nice summary of how this fusing can be accomplished when the batchnorm layer follows the convolutional layer, see here: [https://tehnokv.com/posts/fusing-batchnorm-and-conv/](https://tehnokv.com/posts/fusing-batchnorm-and-conv/).\n",
    "\n",
    "*However*, if the batchnorm precedes a convolutional layer, the fusion can only be accomplished if the convolutional layer does not add any padding to the input. If padding is added, attempts to fuse the batchnorm layer will results in errors at the edges of the output tensors, compared to outputs of the unfused pair of layers. This discrepency will be demo'd in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Conv2D, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the architectures that will be used..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_bn(input_shape, n_chan_out, padding='same'):\n",
    "    # Build architecture with batchnorm after convolution\n",
    "    x = Input(shape=input_shape)\n",
    "    y = Conv2D(n_chan_out, (3,3), padding=padding, name='paired_conv_1')(x)\n",
    "    y = BatchNormalization(axis=-1, name='paired_bn_1', fused=False,\n",
    "                           beta_initializer=tf.initializers.RandomUniform(0, 1),\n",
    "                           gamma_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_mean_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_variance_initializer=tf.initializers.RandomUniform(0, 1))(y)\n",
    "    model = Model(x, y)\n",
    "    return model\n",
    "\n",
    "def build_bn_conv(input_shape, n_chan_out, padding='same'):\n",
    "    # Build architecture with batchnorm before convolution\n",
    "    x = Input(shape=input_shape)\n",
    "    y = BatchNormalization(axis=-1, name='paired_bn_1', fused=False,\n",
    "                           beta_initializer=tf.initializers.RandomUniform(0, 1),\n",
    "                           gamma_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_mean_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_variance_initializer=tf.initializers.RandomUniform(0, 1))(x)\n",
    "    y = Conv2D(n_chan_out, (3,3), padding=padding, name='paired_conv_1')(y)\n",
    "    model = Model(x, y)\n",
    "    return model\n",
    "\n",
    "def build_fused(input_shape, n_chan_out, padding='same'):\n",
    "    # Build fused architecture (one without the explicit batchnorm layer)\n",
    "    x = Input(shape=input_shape)\n",
    "    y = Conv2D(n_chan_out, (3,3), padding=padding, name='fused_conv_1')(x)\n",
    "    model = Model(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define methods for setting parameters of the fused models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_bn_params(model_source, model_target):\n",
    "    names = [layer.name for layer in model_source.layers]\n",
    "    for name in names:\n",
    "        # Assume names have fixed prefix, but model-specific suffixes for multiple conv-bn layer pairs\n",
    "        if name.startswith('paired_bn'):\n",
    "            name_bn = name\n",
    "            name_conv = 'paired_conv' + name[len('paired_bn'):]\n",
    "            name_fuse = 'fused_conv' + name[len('paired_bn'):]\n",
    "\n",
    "            ## Get effective scaling and shifting parameters of the batchnorm\n",
    "            layer_bn = model_source.get_layer(name=name_bn)\n",
    "            params_bn = layer_bn.get_weights()\n",
    "            gamma = params_bn[0]\n",
    "            beta = params_bn[1]\n",
    "            moving_mean = params_bn[2]\n",
    "            moving_variance = params_bn[3]\n",
    "            epsilon = layer_bn.epsilon\n",
    "\n",
    "            m_bn = gamma / np.sqrt(moving_variance + epsilon)\n",
    "            b_bn = beta - m_bn * moving_mean\n",
    "\n",
    "            ## Get weight and bias parameters of the convolution\n",
    "            layer_conv = model_source.get_layer(name=name_conv)\n",
    "            params_conv = layer_conv.get_weights()\n",
    "            w_conv = params_conv[0]\n",
    "            b_conv = params_conv[1]\n",
    "\n",
    "            ## Compute new convolution kernel and bias of composite layer/model\n",
    "            #\n",
    "            # For convolution we have: y = w_conv*x + b_conv\n",
    "            # For batchnorm we have:   z = m_bn*y + b_bn\n",
    "            # Combining we get: z = m_bn*(w_conv*x + b_conv) + b_bn\n",
    "            #                     = [m_bn*w_conv]*x + [m_bn*b_conv + bn]\n",
    "            # So: w_fuse = m_bn * w_conv\n",
    "            #     b_fuse = m_bn * b_conv + b_bn\n",
    "            \n",
    "            # Need to be sure we broadcast across correct dimensions\n",
    "            b_fuse = m_bn * b_conv + b_bn\n",
    "            m_bn = np.reshape(m_bn, (1, 1, 1,  m_bn.size))\n",
    "            w_fuse = w_conv * m_bn\n",
    "\n",
    "            ## Set parameters for composite layer/model\n",
    "            layer_fuse = model_target.get_layer(name=name_fuse)\n",
    "            layer_fuse.set_weights([w_fuse, b_fuse])\n",
    "\n",
    "def fuse_bn_conv_params(model_source, model_target):\n",
    "    names = [layer.name for layer in model_source.layers]\n",
    "    for name in names:\n",
    "        # Assume names have fixed prefix, but model-specific suffixes for multiple conv-bn layer pairs\n",
    "        if name.startswith('paired_bn'):\n",
    "            name_bn = name\n",
    "            name_conv = 'paired_conv' + name[len('paired_bn'):]\n",
    "            name_fuse = 'fused_conv' + name[len('paired_bn'):]\n",
    "\n",
    "            ## Get effective scaling and shifting parameters of the batchnorm\n",
    "            layer_bn = model_source.get_layer(name=name_bn)\n",
    "            params_bn = layer_bn.get_weights()\n",
    "            gamma = params_bn[0]\n",
    "            beta = params_bn[1]\n",
    "            moving_mean = params_bn[2]\n",
    "            moving_variance = params_bn[3]\n",
    "            epsilon = layer_bn.epsilon\n",
    "\n",
    "            m_bn = gamma / np.sqrt(moving_variance + epsilon)\n",
    "            b_bn = beta - m_bn * moving_mean\n",
    "\n",
    "            ## Get weight and bias parameters of the convolution\n",
    "            ## Compute new convolution kernel of composite layer/model\n",
    "            layer_conv = model_source.get_layer(name=name_conv)\n",
    "            params_conv = layer_conv.get_weights()\n",
    "            w_conv = params_conv[0]\n",
    "            b_conv = params_conv[1]\n",
    "\n",
    "            ## Compute new convolution kernel and bias of composite layer/model\n",
    "            #\n",
    "            # **Abusing notion, and recognizing that the multiply sign in the\n",
    "            #   convolution below is actually a multiply-and-sum...\n",
    "            #\n",
    "            # For batchnorm we have:   y = m_bn*x + b_bn\n",
    "            # For convolution we have: z = w_conv*y + b_conv\n",
    "            # Combining we get: z = w_conv*(m_bn*x + b_bn) + b_conv\n",
    "            #                     = [w_conv*m_bn]*x + [w_conv*b_bn + b_conv]\n",
    "            # So: w_fuse = w_conv * m_bn\n",
    "            #     b_fuse = w_conv * b_bn + b_conv\n",
    "\n",
    "            # New convolutional kernel...\n",
    "            m_bn = np.reshape(m_bn, (1, 1, m_bn.size, 1))\n",
    "            w_fuse = w_conv * m_bn\n",
    "            \n",
    "            # New bias...\n",
    "            # Mimic impact of convolution on the shift/offset term of the batchnorm.\n",
    "            # This is slightly incorrect at the x/y spatial edges of the tensors if conv padding is used.\n",
    "            \n",
    "            # b_bn has no x/y spatial dependence, so sum conv weights in x and y...\n",
    "            w_conv_sum = np.sum(w_conv, axis=(0,1))\n",
    "            # mimic the convolution, applied to the shifting parameter of the batchnorm\n",
    "            b_bnconv = np.sum(w_conv_sum * np.reshape(b_bn, (b_bn.size, 1)), axis=0)\n",
    "            b_fuse = b_conv + b_bnconv\n",
    "           \n",
    "            # Set parameters for composite layer/model\n",
    "            layer_fuse = model_target.get_layer(name=name_fuse)\n",
    "            layer_fuse.set_weights([w_fuse, b_fuse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model input/output sizes, and create random input sample for testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed, for repeatability\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "input_shape = (100, 100, 3)\n",
    "n_chan_out = 16\n",
    "\n",
    "# Create random data for model testing through models and measure the output delta\n",
    "n_samples = 1\n",
    "x = tf.random.normal([n_samples] + list(input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and test fused models: Convolution (with padding) followed by batchnorm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models with random parameters\n",
    "padding = 'same' # same or valid\n",
    "model_conv_bn = build_conv_bn(input_shape, n_chan_out, padding=padding)\n",
    "model_fused = build_fused(input_shape, n_chan_out, padding=padding)\n",
    "\n",
    "# Fused conv+batchnorm parameters into new conv parameters\n",
    "fuse_conv_bn_params(model_conv_bn, model_fused)\n",
    "\n",
    "# Put data through both models and measure the output delta\n",
    "y_conv_bn = model_conv_bn.predict(x)\n",
    "y_fused = model_fused.predict(x)\n",
    "\n",
    "delta = y_conv_bn - y_fused\n",
    "mae = np.mean(np.absolute(delta))\n",
    "print('Mean Absolute Error: %0.2e' % (mae))\n",
    "\n",
    "# Show delta\n",
    "delta = delta[0]\n",
    "delta = np.sum(delta, axis=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot()\n",
    "plt.imshow(delta, aspect='equal')\n",
    "plt.colorbar()\n",
    "_ = plt.title('Output difference between Conv2D->BN layers,\\nversus parameter fusion into single Conv2D layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and test fused models: Batchnorm followed by convolution (*with* padding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models with random parameters\n",
    "padding = 'same' # same or valid\n",
    "model_bn_conv = build_bn_conv(input_shape, n_chan_out, padding=padding)\n",
    "model_fused = build_fused(input_shape, n_chan_out, padding=padding)\n",
    "\n",
    "# Fused conv+batchnorm parameters into new conv parameters\n",
    "fuse_bn_conv_params(model_bn_conv, model_fused)\n",
    "\n",
    "# Put data through both models and measure the output delta\n",
    "y_bn_conv = model_bn_conv.predict(x)\n",
    "y_fused = model_fused.predict(x)\n",
    "\n",
    "delta = y_bn_conv - y_fused\n",
    "mae = np.mean(np.absolute(delta))\n",
    "print('Mean Absolute Error: %0.2e' % (mae))\n",
    "\n",
    "# Show delta\n",
    "delta = delta[0]\n",
    "delta = np.sum(delta, axis=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot()\n",
    "plt.imshow(delta, aspect='equal')\n",
    "plt.colorbar()\n",
    "_ = plt.title('Output difference between BN->Conv2D layers,\\nversus parameter fusion into single Conv2D layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and test fused models: Batchnorm followed by convolution (*without* padding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models with random parameters\n",
    "padding = 'valid' # same or valid\n",
    "model_bn_conv = build_bn_conv(input_shape, n_chan_out, padding=padding)\n",
    "model_fused = build_fused(input_shape, n_chan_out, padding=padding)\n",
    "\n",
    "# Fused conv+batchnorm parameters into new conv parameters\n",
    "fuse_bn_conv_params(model_bn_conv, model_fused)\n",
    "\n",
    "# Put data through both models and measure the output delta\n",
    "y_bn_conv = model_bn_conv.predict(x)\n",
    "y_fused = model_fused.predict(x)\n",
    "\n",
    "delta = y_bn_conv - y_fused\n",
    "mae = np.mean(np.absolute(delta))\n",
    "print('Mean Absolute Error: %0.2e' % (mae))\n",
    "\n",
    "# Show delta\n",
    "delta = delta[0]\n",
    "delta = np.sum(delta, axis=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot()\n",
    "plt.imshow(delta, aspect='equal')\n",
    "plt.colorbar()\n",
    "_ = plt.title('Output difference between BN->Conv2D layers,\\nversus parameter fusion into single Conv2D layer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow2",
   "language": "python",
   "name": "env_tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

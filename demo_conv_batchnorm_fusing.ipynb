{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusing convolutional and batchnorm layers in TensorFlow\n",
    "\n",
    "- Batchnorm layers can be fused with preceding 2D convolutional layers, into a single convolutional layer.\n",
    "- Batchnorm layers *cannot* be fused with subseqeunt 2D convolutional layers, into a single convolutional layer, *if* that convolutional layer adds padding to its input.\n",
    "- This script demos both types of fusion, and highlights how the fusion can fail in the latter case when padding is used.\n",
    "- Thus, in some models implemented on specialized hardware (e.g., Edge TPU), it is desirable (necessary!) to have an API that implements a batchnorm layer, or at least the broadcasted scaling and shifting that can mimic a static batchnorm layer after training. Moreover, in the case of a sequence of (Conv2D->RELU->BN) layers, the batchnorm layer clearly cannot be fused with the convolutional layer.\n",
    "\n",
    "Batchnorm layers scale and shift the input data, providing normalized data to the subsequent layer. In the original batchnorm [publication](https://arxiv.org/abs/1502.03167), bathnorm layers follow convolutional layers, and precede RELU layers (Conv2D->BN->RELU). Since that publication, many researchers have used batchnorm layers that follow the RELU layer (Conv2D->RELU->BN), claiming superior results.\n",
    "\n",
    "After training, if the moving mean and moving standard deviation of the batchnorm layer are kept fix, then the scaling and shifting parameters *might* be \"fused\" with a preceding or subsequent convolutional layer (by scaling and shifting the parameters of the convolutional layer), thereby allowing the explicit batchnorm layer to be removed (as it will be implicitly implemented by the convolutional layer).\n",
    "\n",
    "For a nice summary of how this fusing can be accomplished when the batchnorm layer follows the convolutional layer, see here: [https://tehnokv.com/posts/fusing-batchnorm-and-conv/](https://tehnokv.com/posts/fusing-batchnorm-and-conv/).\n",
    "\n",
    "*However*, if the batchnorm precedes a convolutional layer, the fusion can only be accomplished if the convolutional layer does not add any padding to the input. If padding is added, attempts to fuse the batchnorm layer will results in errors at the edges of the output tensors, compared to outputs of the unfused pair of layers. This discrepency will be demo'd in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Conv2D, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the architectures that will be used..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_bn(input_shape, n_chan_out, padding='same'):\n",
    "    # Build architecture with batchnorm after convolution\n",
    "    x = Input(shape=input_shape)\n",
    "    y = Conv2D(n_chan_out, (3,3), padding=padding, name='bnconv_conv_1')(x)\n",
    "    y = BatchNormalization(axis=-1, name='bnconv_bn_1', fused=False,\n",
    "                           beta_initializer=tf.initializers.RandomUniform(0, 1),\n",
    "                           gamma_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_mean_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_variance_initializer=tf.initializers.RandomUniform(0, 1))(y)\n",
    "    model = Model(x, y)\n",
    "    return model\n",
    "\n",
    "def build_bn_conv(input_shape, n_chan_out, padding='same'):\n",
    "    # Build architecture with batchnorm before convolution\n",
    "    x = Input(shape=input_shape)\n",
    "    y = BatchNormalization(axis=-1, name='bnconv_bn_1', fused=False,\n",
    "                           beta_initializer=tf.initializers.RandomUniform(0, 1),\n",
    "                           gamma_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_mean_initializer=tf.initializers.RandomNormal(0, 0.5),\n",
    "                           moving_variance_initializer=tf.initializers.RandomUniform(0, 1))(x)\n",
    "    y = Conv2D(n_chan_out, (3,3), padding=padding, name='bnconv_conv_1')(y)\n",
    "    model = Model(x, y)\n",
    "    return model\n",
    "\n",
    "def build_fused(input_shape, n_chan_out, padding='same'):\n",
    "    # Build fused architecture (one without the explicit batchnorm layer)\n",
    "    x = Input(shape=input_shape)\n",
    "    y = Conv2D(n_chan_out, (3,3), padding=padding, name='bnconv_comp_1')(x)\n",
    "    model = Model(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define methods for setting parameters of the fused models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_bn_params(model_source, model_target):\n",
    "    names = [layer.name for layer in model_source.layers]\n",
    "    for name in names:\n",
    "        if name.startswith('bnconv_bn'):\n",
    "            name_bn = name\n",
    "            name_conv = 'bnconv_conv' + name[len('bnconv_bn'):]\n",
    "            name_comp = 'bnconv_comp' + name[len('bnconv_bn'):]\n",
    "\n",
    "            layer_bn = model_source.get_layer(name=name_bn)\n",
    "            params_bn = layer_bn.get_weights()\n",
    "            gamma = params_bn[0]\n",
    "            beta = params_bn[1]\n",
    "            moving_mean = params_bn[2]\n",
    "            moving_variance = params_bn[3]\n",
    "            epsilon = layer_bn.epsilon\n",
    "\n",
    "            m_bn = gamma / np.sqrt(moving_variance + epsilon)\n",
    "            b_bn = beta - m_bn * moving_mean\n",
    "\n",
    "            ## Compute new convolution kernel of composite layer/model\n",
    "            layer_conv = model_source.get_layer(name=name_conv)\n",
    "            params_conv = layer_conv.get_weights()\n",
    "            w_conv = params_conv[0]\n",
    "            b_conv = params_conv[1]\n",
    "\n",
    "            b_comp = m_bn * b_conv + b_bn\n",
    "            m_bn = np.reshape(m_bn, (1, 1, 1,  m_bn.size))\n",
    "            w_comp = w_conv * m_bn\n",
    "\n",
    "            ## Compute new convolution bias of composite layer/model\n",
    "            # Mimic impact of convolution on the shift/offset term of the batchnorm.\n",
    "            # This is slightly incorrect at the x/y spatial edges of the tensors.\n",
    "            # w_conv_sum = np.sum(w_conv, axis=(0,1))    # b_bn has no x/y spatial dependence, so sum conv weights in x and y.\n",
    "            # b_bnconv = np.sum(w_conv_sum * np.reshape(b_bn, (b_bn.size, 1)), axis=0) # mimic the convolution\n",
    "            # b_comp = b_conv + b_bnconv\n",
    "\n",
    "            # Set parameters for composite layer/model\n",
    "            layer_comp = model_target.get_layer(name=name_comp)\n",
    "            layer_comp.set_weights([w_comp, b_comp])\n",
    "\n",
    "\n",
    "def fuse_bn_conv_params(source_model, target_model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and test fused models: Convolution followed by batchnorm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed, for repeatability\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "input_shape = (100, 100, 3)\n",
    "n_chan_out = 16\n",
    "\n",
    "# Create random data for model testing through models and measure the output delta\n",
    "n_samples = 1\n",
    "x = tf.random.normal([n_samples] + list(input_shape))\n",
    "\n",
    "# Build models with random parameters\n",
    "padding = 'same' # same or valid\n",
    "model_conv_bn = build_conv_bn(input_shape, n_chan_out, padding=padding)\n",
    "model_fused = build_fused(input_shape, n_chan_out, padding=padding)\n",
    "\n",
    "# Fused conv+batchnorm parameters into new conv parameters\n",
    "fuse_conv_bn_params(model_conv_bn, model_fused)\n",
    "\n",
    "# Put data through both models and measure the output delta\n",
    "y_conv_bn = model_conv_bn.predict(x)\n",
    "y_fused = model_fused.predict(x)\n",
    "\n",
    "delta = y_conv_bn - y_fused\n",
    "mae = np.mean(np.absolute(delta))\n",
    "print('Mean Absolute Error: %0.2e' % (mae))\n",
    "\n",
    "# Show delta\n",
    "delta = delta[0]\n",
    "delta = np.sum(delta, axis=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot()\n",
    "plt.imshow(delta)\n",
    "plt.colorbar()\n",
    "plt.title('Difference between Conv2D->BN layers, versus fusion into single Conv2D layer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow2",
   "language": "python",
   "name": "env_tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
